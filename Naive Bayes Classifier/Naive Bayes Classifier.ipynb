{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting SPAM emails with a Naive Bayes Classifier\n",
    "\n",
    "The Naive Bayes Classifier is based on one of the most important results in Statistics: The Bayes Theorem. We will see how this theorem can be employed to determine if an email is SPAM or not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true
   },
   "source": [
    "## Bayes' Theorem\n",
    "\n",
    "You probably remember something called \"conditional probability.\" Let us assume we have two events A and B that migh be related. Also, suppose that we know that event B has occured, then we might ask what is the probability that event A occurs given that event B already happened. This is written in mathematical terms as follows: $P(A|B)$. This quantity is equal to\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A|B)=\\frac{P(A\\cap B)}{P(B)}\n",
    "\\end{align}\n",
    "$$.\n",
    "\n",
    "By the way, when events A and B are independent, we have that $P(A|B)=P(A)$; this means that the ocurrence of B does not influence whatsoever the probability of A. The latter implies that $P(A\\cap B)=P(A)P(B)$.\n",
    "\n",
    "On the other hand, we could also ask what is the probability that B occurs given that A happened:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(B|A)=\\frac{P(A\\cap B)}{P(A)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Then, we have that $P(A|B)P(B)=P(B|A)P(A)=P(A\\cap B)$. Therefore,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(A|B)=\\frac{P(B|A)P(A)}{P(B)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "This last expression is known as **Bayes' Theorem**. \n",
    "\n",
    "The term $P(A|B)$ is known as the *posterior probability*, the term $P(A)$ is defined as *a prior probability*, $P(B)$ is a *marginal probability*, and $P(B|A)$ is a conditional probability that can be understood as the likelihood of A given a fixed B: $L(A|B)=P(B|A)$.\n",
    "\n",
    "Let us see Bayes' Theorem in action. Say there is a rare disease that just one out of a thousand people has it. Also, assume there is test for this disease that identifies correctly 99% of the time the people that have the disease. Then, if a person tests positive, what is the probability that this person has the disease?\n",
    "\n",
    "Let us define two events: D is the event of a person having the disease, T is the event that a test gives a positive result. Then, to answer the question we just asked, we need to compute $P(D|T)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(D|T)=\\frac{P(T|D)P(D)}{P(T)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To begin with, we have that $P(D)=0.001$ and $P(T|D)=0.99$. As for $P(T)$, this can be calculated as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(T)&=P(T|D)P(D)+P(T|\\bar{D})P(\\bar{D})\\\\\n",
    "\\\\\n",
    "&=(0.99)(0.001)+(0.01)(0.999)\\\\\n",
    "\\\\\n",
    "&=0.01098.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(D|T)=\\frac{(0.99)(0.001)}{0.01098}=0.09016...\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "It is worth to consider the following situation: So our hypothetical person realized that the probability of having the disease is not that high, so he/she goes to another lab and takes the test again. If the result is, once again, positive, what is the probability that the person has the disease?\n",
    "\n",
    "In this case, our prior probability $P(D)$ is no longer 0.001 but 0.09016. Thus, we have to update both the posterior probability $P(D|T)$ and the marginal probability $P(T)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(D|T)&=\\frac{P(T|D)P(D)}{P(T)}\\\\\n",
    "\\\\\n",
    "&=\\frac{P(T|D)P(D)}{P(T|D)P(D)+P(T|\\bar{D})P(\\bar{D})}\\\\\n",
    "\\\\\n",
    "&=\\frac{(0.99)(0.0916)}{(0.99)(0.0916)+(0.01)(0.9098)}\\\\\n",
    "\\\\\n",
    "&=0.9075.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "As we can see, our hypothetical character should be worried now. \n",
    "\n",
    "By the way, the latter example was taken from https://www.youtube.com/watch?v=R13BD8qKeTg. Let us now import some very needed libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## General Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to load the data we will work with. This data can be downloaded from https://www.kaggle.com/uciml/sms-spam-collection-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('spam.csv', encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the data\n",
    "\n",
    "Before going any further, it is clear that our data needs some cleaning. For instance, the **unnamed columns** can be removed. Speaking of columns, some \"renaming\" would be desirable for the sake of clarity. Also, we would like use a \"binary variable\" for categorizing the emails: 0 for **not spam** and 1 for **spam**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data_clean = data\n",
    "data_clean['spam'] = data_clean['v1'].map({'ham' : 0, 'spam' : 1})\n",
    "data_clean = data_clean.drop(columns=['v1', 'Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'])\n",
    "data_clean = data_clean.rename(columns={'v2' : 'email'})\n",
    "data_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks nicer, doesn't it? But this is just the beggining. At this point we need to process the emails and turn them into something that our model will \"digest\" much more easily. In order to do this we need some **Natural Language Processing** (NLP): \"NLP is a subfield of linguistics, computer science, and artificial intelligence concerned with the interactions between computers and human language, in particular how to program computers to process and analyze large amounts of natural language data,\" according to Wikipedia."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Processing\n",
    "\n",
    "Text preprocessing is crucial before building a proper NLP model. Here are the important steps we are going to carry out:\n",
    "\n",
    "1. Converting words to lower case.\n",
    "2. Removing special characters.\n",
    "3. Removing stopwords.\n",
    "4. Stemming and lemmatization.\n",
    "\n",
    "More on steps three and four later. For now let us proceed with step number one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lower case and special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "data_clean['email'] = data_clean['email'].apply(lambda x : x.lower())\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us do step number two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['email'] = data_clean['email'].apply(lambda x : re.sub('[^A-Za-z0-9 ]+', ' ', x))\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that we have assumed that it is \"safe\" to turn the characters of the emails into lower case letters and that special characters do not posses relevant information. This may be okay for this type of application, but for, say, sentiment analysis, we might need to reconsider this since special characters like exclamation points are used to convey certain emotions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "At this point you migh be wondering \"what are stop words?\" Well, these are words that are encountered very frequently in a given language but do not carry useful information, thus it is a good practice to remove them. Before doing this, let us take a look into the stop words of the English language:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "stop_words = stopwords.words('english')\n",
    "print(stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now onto removing stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(message):\n",
    "    \n",
    "    words = word_tokenize(message)\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_clean['email'] = data_clean['email'].apply(remove_stop_words)\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that apart from removing stop words we did something else, that \"something else\" is called **tokenization**: Tokenization is defined as splitting a text into small units known as **tokens**. We might think that this is as simple as taking a text and each time we find a space between words we split there, but the process is more involved than that. The method `word_tokenize` is clever enough to do thing such as this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_tokenize(\"There's something I'd like to know, dude.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming and lemmatization\n",
    "\n",
    "It is natural that in any language we will use variations of the same word, e.g., \"run\", \"ran\", and \"running\". These variations are called **inflections**. Even more, there are words that have similar meanings such as \"democracy\", \"democratic\", and \"democratization\". The goal of both stemming and lemmatization is to turn either inflections or derivationally related forms of a word into a common base form. For instance:\n",
    "\n",
    "*Lemmatization:* am, are, is $\\Rightarrow$ be.\n",
    "\n",
    "*Stemming:* car, cars $\\Rightarrow$ car.\n",
    "\n",
    "Stemming is considered a crude heuristic process that chops off parts of a word by taking into account common prefixes and suffixes. On the other hand, lemmatization takes into consideration the grammar of the word and attemps to find the root word. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## modules for \n",
    "## stemming and lemmatization \n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "#nltk.download('wordnet')\n",
    "\n",
    "Porter = PorterStemmer()\n",
    "Lemma = WordNetLemmatizer()\n",
    "\n",
    "print(Porter.stem(\"car\"))\n",
    "print(Porter.stem(\"cars\"))\n",
    "\n",
    "print(Lemma.lemmatize(\"am\", wordnet.VERB))\n",
    "print(Lemma.lemmatize(\"are\", wordnet.VERB))\n",
    "print(Lemma.lemmatize(\"is\", wordnet.VERB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the meantime, for this application, we will stick to *stemming*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean['email'] = data_clean['email'].apply(lambda x : [Porter.stem(word) for word in x])\n",
    "data_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and testing sets\n",
    "\n",
    "When we are developing a model we do not use all of our data for training, what we do is that we divide the data we posses into two sets: the training set and the testing set. A general rule of thumb is to use 80% of the data for training and 20% for testing our model. There are variations of this depending on the circumstances, but, in general, this is a good starting point. By the way, all the examples of our training data should be picked randomly to avoid any bias; it is not a good practice to pick these examples in a deterministic fashion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1337) \n",
    "number_of_rows = data_clean.shape[0]\n",
    "index_train = np.random.choice(range(number_of_rows), int(0.9 * number_of_rows), replace=False)\n",
    "index_test = np.asarray(list(set(range(number_of_rows)) - set(index_train)))\n",
    "train_set = data_clean.iloc[index_train] \n",
    "test_set = data_clean.iloc[index_test] \n",
    "print(train_set.shape)\n",
    "print(test_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes Classifier\n",
    "\n",
    "Let us talk about emails now. Let $W$ be the set of all English words and let an email $m$ be a set of words that belong to $W$: $m=\\{w_1,w_2,\\dots,w_n\\}$. If we want to know what is the probability that said email $m$ is spam we can use, as expected, Bayes' Theorem:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(spam|m)&=\\frac{P(m|spam)P(spam)}{P(m)}\\\\\n",
    "\\\\\n",
    "&=\\frac{P(w_1\\cap w_2\\cap\\cdots\\cap w_n|spam)P(spam)}{P(w_1\\cap w_2\\cap\\cdots\\cap w_n)}\\\\\n",
    "\\\\\n",
    "&=\\frac{P(w_1\\cap w_2\\cap\\cdots\\cap w_n|spam)P(spam)}{P(w_1\\cap w_2\\cap\\cdots\\cap w_n|spam)P(spam)+P(w_1\\cap w_2\\cap\\cdots\\cap w_n|not~spam)P(not~spam)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "At this point it is a good idea to focus our attention on the numerator of the last expression. Notice that we have $P(w_1\\cap w_2\\cap\\cdots\\cap w_n|spam)P(spam)$, which is equivalent to the joint probability distribution of $P(w_1\\cap w_2\\cap\\cdots\\cap w_n\\cap spam)$. By the multiplication rule, this expression can be rewritten as follows:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(w_1\\cap w_2\\cap\\cdots\\cap w_n\\cap spam) = P(spam)P(w_1|spam)P(w_2|w_1\\cap spam)\\cdots P(w_n|\\cap_{i=1}^{n-1}w_i\\cap spam).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "And here it comes the \"naive assumption\": given the spam category, we assume that all features of the model, in this case the words of the email, are **mutually and conditionally independent** on the spam category:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(w_i|w_{i+1}\\cap\\cdots\\cap w_n\\cap spam) = P(w_i|spam).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "What this expression is telling us is that the probability of having word $w_i$ in a spam message is not affected by the presence of the set of words $\\{w_{i+1},\\dots,w_n\\}$ in said message, what we just need to consider is that such email is spam. Consider the sentence \"we need your info\" and assume that we know we are dealing with an email that is spam. Then, if the naive assumption is true, this could happen:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\text{need}|\\text{we}\\cap\\text{your}\\cap\\text{info}\\cap spam) = P(\\text{need}|spam).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "However, this is not usually true, what we have, in general, is this:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(\\text{need}|\\text{we}\\cap\\text{your}\\cap\\text{info}\\cap spam) \\neq P(\\text{need}|spam).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "For this reason we say that this assumption is naive. Nevertheless, in practice, this classifier works very well in many situations.\n",
    "\n",
    "Let us go back to the numerator. Taking into account our naive premise, the joint probability distribution can be expressed as\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(w_1\\cap w_2\\cap\\cdots\\cap w_n\\cap spam) = P(spam)P(w_1|spam)P(w_2|spam)\\cdots P(w_n|spam).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Therefore, the probability that a given message $m=\\{w_1,w_2,\\dots,w_n\\}$ is spam can be computed with this expression:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(spam|w_1\\cap w_2\\cap\\cdots\\cap w_n) = \\frac{P(w_1|spam)P(w_2|spam)\\cdots P(w_n|spam)P(spam)}{P(w_1\\cap w_2\\cap\\cdots\\cap w_n)}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "You migh be asking, well, how can we classify an email as spam with all this? There are two options: the **Probabilistic Model** and the **Maximum A Posteriori Model (MAP)**.\n",
    "\n",
    "#### Probabilistic Model \n",
    "\n",
    "Given a threshold $p$, we classify an email as spam if this condition holds:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(spam|w_1\\cap w_2\\cap\\cdots\\cap w_n) > p.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "#### Maximum A Posteriori Model (MAP)\n",
    "\n",
    "An email is categorized as spam if \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(spam|w_1\\cap w_2\\cap\\cdots\\cap w_n) > P(not~spam|w_1\\cap w_2\\cap\\cdots\\cap w_n),\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "which is equivalent to\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(w_1|spam)P(w_2|spam)\\cdots P(w_n|spam)P(spam) > P(w_1|not~spam)P(w_2|not~spam)\\cdots P(w_n|not~spam)P(not~spam).\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Notice that it is not necessary to calculate $P(w_1\\cap w_2\\cap\\cdots\\cap w_n)$. For classifying emails we will employ this method.\n",
    "\n",
    "\n",
    "## Training the Model\n",
    "\n",
    "Let $W_{\\text{t}}$ be the set that contains all the words of the emails that belong to the training set. As expected, $W_{\\text{t}}=W_{\\text{t-~s}}~\\cup W_{\\text{t-s}}$ and $W_{\\text{t-~s}}~\\cap W_{\\text{t-s}}=\\emptyset$, where $W_{\\text{t-~s}}~$ and $W_{\\text{t-s}}~$ are the subsets of the training set that contain non-spam and spam emails, respectively. In the training phase we need to compute the following probabilities for the training set:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(w_i|spam), & ~\\forall w_i\\in W_{\\text{t-s}}\\\\\n",
    "\\\\\n",
    "P(w_i|not~spam), & ~\\forall w_i\\in W_{\\text{t-~s}}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Notice that \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(w_i|spam)=\\frac{\\text{number of ocurrences of $w_i$ in spam emails}}{\\text{total number of words of spam emails}}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Similarly, \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(w_i|not~spam)=\\frac{\\text{number of ocurrences of $w_i$ in non-spam emails}}{\\text{total number of words of non-spam emails}}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Also, we need to calculate $P(spam)$ and $P(not~spam)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P(spam)&=\\frac{|W_{\\text{t-s}}~|}{|W_{\\text{t}}|}\\\\\n",
    "\\\\\n",
    "P(not~spam)&=\\frac{|W_{\\text{t-~s}}~~|}{|W_{\\text{t}}|}.\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "By the way, this way of computing the probabilities is based on the **Bag of Words** model, in which we are interested in the frequencies of each of the words of a corpus without taking into consideration neither grammar  nor order.\n",
    "\n",
    "This is not the only model at our disposal, another popular option is the **Term Frequency-Inverse Document Frequency (TF-IDF)** model, which is based on information theory. For now, we will focus on the bag-of-words approach, but if you want to know more this is a good starting point: https://en.wikipedia.org/wiki/Tfâ€“idf."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_spam = train_set[train_set['spam'] == 1].shape[0] / train_set.shape[0]\n",
    "p_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_not_spam = train_set[train_set['spam'] == 0].shape[0] / train_set.shape[0]\n",
    "p_not_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def bag_of_words(corpus):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a corpus, i.e., the set of processed emails, and\n",
    "    returns a dictionary in which each item is a unique word and each word \n",
    "    has its corresponding number of ocurrences in the corpus. \n",
    "    \"\"\"\n",
    "    bag_of_words = {}\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "    \n",
    "    return bag_of_words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def probability_words(df):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function receives a dataframe of either spam emails or non-spam emails \n",
    "    that has been processed as shown above. Using the dictionary that is returned\n",
    "    by the previous function and the data contained in df, this function computes \n",
    "    the probability of each word in bag_of_words. The probabilities are returned \n",
    "    in probability_words.\n",
    "    \"\"\"\n",
    "    \n",
    "    probability_words = {}\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\"\n",
    "        \n",
    "    return probability_words   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_spam_words = probability_words(train_set[train_set['spam'] == 1])\n",
    "probability_spam_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability_non_spam_words = probability_words(train_set[train_set['spam'] == 0])\n",
    "probability_non_spam_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hide_input": false
   },
   "outputs": [],
   "source": [
    "def classify_email(email):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function is the equivalent of the predict method in scikit-learn. \n",
    "    In this case it receives a list in which each element is a processed \n",
    "    word of said message, and returns a 1 if such email is spam, or 0 otherwise.\n",
    "    For this purpose, this function needs the probabilities that were computed\n",
    "    by the function probability_words.\n",
    "    \"\"\"\n",
    "    \n",
    "    \"INSERT YOUR CODE HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_set_hat = test_set.copy()\n",
    "test_set_hat['prediction'] = test_set['email'].apply(classify_email)\n",
    "test_set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "So we have built the Naive Bayes Classifier and we have trained it, but is it good? To know how good our model is we need **evaluation metrics**. There are tons of metrics, and the ideal metric, or metrics, will have to be chosen depending on what is important for your particular application. For now, we will mention a few of the most common, however, before going any further, we need to say a few things about the **confusion matrix**.\n",
    "\n",
    "#### Confusion Matrix\n",
    "\n",
    "A confusion matrix is a table that allows us to visualize the performance of a classification algorithm. \n",
    "\n",
    "<img src=\"confusion.png\" alt=\"Drawing\" style=\"width: 700px;\"/>\n",
    "\n",
    "This type of table receives this name because it lets us observe whether an algorithm is mislabeling two classes (Image taken from https://en.wikipedia.org/wiki/Precision_and_recall). \n",
    "\n",
    "#### Accuracy\n",
    "\n",
    "Accuracy is defined as follows:\n",
    "\n",
    "$$\n",
    "\\text{Accuracy}=\\frac{\\text{true positives} + \\text{true negatives}}{\\text{true positives} + \\text{false positives} +  \\text{true negatives} + \\text{false negatives}}.\n",
    "$$\n",
    "\n",
    "This metric is useful when both classes are equally important and when we have balanced set, which is not quite the case in this application.\n",
    "\n",
    "#### Precision\n",
    "\n",
    "The ratio of positive cases that were correctly labeled over all the examples that were classified as positive is called **precision**:\n",
    "\n",
    "$$\n",
    "\\text{Precision}=\\frac{\\text{true positives}}{\\text{true positives} + \\text{false positives}}.\n",
    "$$\n",
    "\n",
    "When we are interested in reducing the amount of false positives and we have imbalanced sets, precision is a good choice as an evaluation metric. In fact, for this application, this metric is appriopriate since we are interested in detecting spam emails: spam is the positive category, if a regular email is classified as spam (false positive), we are sending emails that are important for us to the spam folder; however, if a spam email is labeled as not-spam, said email will end up in our inbox, which is not as serious as not reading an email that we are expecting. Also, keep in mind that our sets are imbalanced: the majority of our emails in the data are not spam.\n",
    "\n",
    "#### Recall\n",
    "\n",
    "Recall is the ratio of the examples that were correclty identified as a positive case over all the true positives examples in our data. This metric can be understood as the sensitivity of our model:\n",
    "\n",
    "$$\n",
    "\\text{Recall}=\\frac{\\text{true positives}}{\\text{true positives} + \\text{false negatives}}.\n",
    "$$\n",
    "\n",
    "If we want to pay special attention to the false negatives that our model is detecting, and if our sets are imbalanced, then this can be one of our performance metrics. Say we want to build a model that detects a dangerous disease. In this case, we are not interested in telling a person that he/she does not have the disease when that is not the case (false negative). \n",
    "\n",
    "#### F1 Score\n",
    "\n",
    "The F1 score is equal to the harmonic mean of precision and recall. It is useful when we want to have a balance between precision and recall and when we do not have balanced sets (large number of actual negatives). It is defined as \n",
    "\n",
    "$$\n",
    "\\text{F1 Score}=2\\frac{\\text{Precision} * \\text{Recall}}{\\text{Precision} + \\text{Recall}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def performance_metrics(results):\n",
    "    \n",
    "    positives = results[['spam', 'prediction']][results['spam'] == 1]\n",
    "    negatives = results[['spam', 'prediction']][results['spam'] == 0]\n",
    "    \n",
    "    true_negatives = negatives[negatives['spam'] == negatives['prediction']].shape[0]\n",
    "    false_positives = negatives[negatives['spam'] != negatives['prediction']].shape[0]\n",
    "    true_positives = positives[positives['spam'] == positives['prediction']].shape[0]\n",
    "    false_negatives = positives[positives['spam'] != positives['prediction']].shape[0]\n",
    "    \n",
    "    confusion_matrix = {'actual positives' : [true_positives, false_negatives], \n",
    "                        'actual negatives' : [false_positives, true_negatives]}\n",
    "    \n",
    "    confusion_matrix_df = pd.DataFrame.from_dict(confusion_matrix, orient='index', \n",
    "                                                 columns=['predicted positives', 'predicted negatives'])\n",
    "    \n",
    "    accuracy = (true_positives + true_negatives) / (true_positives + false_positives +  true_negatives + false_negatives)\n",
    "    precission = true_positives / (true_positives + false_positives)\n",
    "    recall = true_positives / (true_positives + false_negatives)\n",
    "    f1_score = 2 * (precission * recall) / (precission + recall)\n",
    "    \n",
    "    metrics = {'Accuracy' : accuracy, 'Precission' : precission, 'Recall' : recall, 'F1 Score' : f1_score}\n",
    "    \n",
    "    metrics_df = pd.DataFrame.from_dict(metrics, orient='index', columns=['Metrics'])\n",
    "    \n",
    "    return confusion_matrix_df, metrics_df   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix, metrics = performance_metrics(test_set_hat)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model has good precision, but its recall is poor: a lot of emails that are spam were labeled as not-spam. Although this is not a serious issue for this type of application, this suggests that we should get more examples of spam emails if we want to increase the sensitivity of our model or try different strategies such as n-grams, TF-IDF, etc., or both things. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliography\n",
    "\n",
    "[1] *Hastie, T., Tibshirani, R., Friedman, J. H., \"The elements of statistical learning: data mining, inference, and prediction,\" New York, Springer, 2009.*\n",
    "\n",
    "[2] https://www.regular-expressions.info/\n",
    "\n",
    "[3] https://www.nltk.org/"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
